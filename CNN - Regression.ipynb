{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_close(data):\n",
    "    f = open(data, 'r').readlines()[1:]\n",
    "    raw_data = []\n",
    "    raw_dates = []\n",
    "    for line in f:\n",
    "        try:\n",
    "            close_price = float(line.split(',')[4])\n",
    "            raw_data.append(close_price)\n",
    "            raw_dates.append(line.split(',')[0])\n",
    "        except:\n",
    "            continue\n",
    "    return raw_data, raw_dates\n",
    "\n",
    "def load_returns(data):\n",
    "    f = open(data, 'r').readlines()[1:]\n",
    "    raw_data = []\n",
    "    raw_dates = []\n",
    "    for line in f:\n",
    "        try:\n",
    "            open_price = float(line.split(',')[1])\n",
    "            close_price = float(line.split(',')[4])\n",
    "            raw_data.append(close_price - open_price)\n",
    "            raw_dates.append(line.split(',')[0])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return raw_data[::-1], raw_dates[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n",
    "    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n",
    "    The model can handle multiple input timeseries (`nb_input_series`) and multiple prediction targets (`nb_outputs`).\n",
    "    :param int window_size: The number of previous timeseries values to use as input features.  Also called lag or lookback.\n",
    "    :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n",
    "      The `X` input to ``fit()`` should be an array of shape ``(n_instances, window_size, nb_input_series)``; each instance is\n",
    "      a 2D array of shape ``(window_size, nb_input_series)``.  For example, for `window_size` = 3 and `nb_input_series` = 1 (a\n",
    "      single timeseries), one instance could be ``[[0], [1], [2]]``. See ``make_timeseries_instances()``.\n",
    "    :param int nb_outputs: The output dimension, often equal to the number of inputs.\n",
    "      For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n",
    "      usually the value(s) predicted to come after the last value in that input instance, i.e., the next value\n",
    "      in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``.\n",
    "    :param int filter_length: the size (along the `window_size` dimension) of the sliding window that gets convolved with\n",
    "      each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed\n",
    "      to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window\n",
    "      dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not\n",
    "      meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "    :param int nb_filter: The number of different filters to learn (roughly, input patterns to recognize).\n",
    "    \"\"\"\n",
    "    model = Sequential((\n",
    "        # The first conv layer learns `nb_filter` filters (aka kernels), each of size ``(filter_length, nb_input_series)``.\n",
    "        # Its output will have shape (None, window_size - filter_length + 1, nb_filter), i.e., for each position in\n",
    "        # the input timeseries, the activation of each filter at that position.\n",
    "        #Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n",
    "        Convolution1D(input_shape=(window_size, nb_input_series), \n",
    "                      kernel_size=filter_length, activation=\"relu\", filters=nb_filter),\n",
    "        MaxPooling1D(),     # Downsample the output of convolution by 2X.\n",
    "        #Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n",
    "        Convolution1D(kernel_size=filter_length, activation=\"relu\", filters=nb_filter),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='linear'),     # For binary classification, change the activation to 'sigmoid'\n",
    "    ))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    # To perform (binary) classification instead:\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    \"\"\"Make input features and prediction targets from a `timeseries` for use in machine learning.\n",
    "    :return: A tuple of `(X, y, q)`.  `X` are the inputs to a predictor, a 3D ndarray with shape\n",
    "      ``(timeseries.shape[0] - window_size, window_size, timeseries.shape[1] or 1)``.  For each row of `X`, the\n",
    "      corresponding row of `y` is the next value in the timeseries.  The `q` or query is the last instance, what you would use\n",
    "      to predict a hypothetical next (unprovided) value in the `timeseries`.\n",
    "    :param ndarray timeseries: Either a simple vector, or a matrix of shape ``(timestep, series_num)``, i.e., time is axis 0 (the\n",
    "      row) and the series is axis 1 (the column).\n",
    "    :param int window_size: The number of samples to use as input prediction features (also called the lag or lookback).\n",
    "    \"\"\"\n",
    "    timeseries = np.asarray(timeseries)\n",
    "    assert 0 < window_size < timeseries.shape[0]\n",
    "    X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n",
    "    y = timeseries[window_size:]\n",
    "    q = np.atleast_3d([timeseries[-window_size:]])\n",
    "    return X, y, q\n",
    "\n",
    "\n",
    "def evaluate_timeseries(timeseries, window_size):\n",
    "    \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n",
    "    as input features and evaluate its performance.\n",
    "    :param ndarray timeseries: Timeseries data with time increasing down the rows (the leading dimension/axis).\n",
    "    :param int window_size: The number of previous timeseries values to use to predict the next.\n",
    "    \"\"\"\n",
    "    filter_length = 5\n",
    "    nb_filter = 4\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T       # Convert 1D vectors to 2D column vectors\n",
    "\n",
    "    nb_samples, nb_series = timeseries.shape\n",
    "    print('\\n\\nTimeseries ({} samples by {} series):\\n'.format(nb_samples, nb_series), timeseries)\n",
    "    model = make_timeseries_regressor(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n",
    "    print('\\n\\nModel with input size {}, output size {}, {} conv filters of length {}'.format(model.input_shape, model.output_shape, nb_filter, filter_length))\n",
    "    model.summary()\n",
    "\n",
    "    X, y, q = make_timeseries_instances(timeseries, window_size)\n",
    "    print('\\n\\nInput features:', X, '\\n\\nOutput labels:', y, '\\n\\nQuery vector:', q, sep='\\n')\n",
    "    test_size = int(0.01 * nb_samples)           # In real life you'd want to use 0.2 - 0.5\n",
    "    X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    print('\\n\\nactual', 'predicted', sep='\\t')\n",
    "    for actual, predicted in zip(y_test, pred.squeeze()):\n",
    "        print(actual.squeeze(), predicted, sep='\\t')\n",
    "\n",
    "    print('next', model.predict(q).squeeze(), sep='\\t')\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simple single timeseries vector prediction\n",
      "\n",
      "\n",
      "Timeseries (4103 samples by 1 series):\n",
      " [[  42.52629346]\n",
      " [  42.82264393]\n",
      " [  43.00786298]\n",
      " ..., \n",
      " [ 128.91      ]\n",
      " [ 128.97      ]\n",
      " [ 129.18      ]]\n",
      "\n",
      "\n",
      "Model with input size (None, 120, 1), output size (None, 1), 4 conv filters of length 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_29 (Conv1D)           (None, 116, 4)            24        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 58, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 54, 4)             84        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 27, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 108)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 109       \n",
      "=================================================================\n",
      "Total params: 217\n",
      "Trainable params: 217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Input features:\n",
      "[[[  42.52629346]\n",
      "  [  42.82264393]\n",
      "  [  43.00786298]\n",
      "  ..., \n",
      "  [  38.86739936]\n",
      "  [  38.60654433]\n",
      "  [  39.09098939]]\n",
      "\n",
      " [[  42.82264393]\n",
      "  [  43.00786298]\n",
      "  [  43.63760774]\n",
      "  ..., \n",
      "  [  38.60654433]\n",
      "  [  39.09098939]\n",
      "  [  39.35184442]]\n",
      "\n",
      " [[  43.00786298]\n",
      "  [  43.63760774]\n",
      "  [  43.26716965]\n",
      "  ..., \n",
      "  [  39.09098939]\n",
      "  [  39.35184442]\n",
      "  [  39.2400494 ]]\n",
      "\n",
      " ..., \n",
      " [[ 120.30522013]\n",
      "  [ 120.52421027]\n",
      "  [ 120.97214465]\n",
      "  ..., \n",
      "  [ 128.4       ]\n",
      "  [ 128.36      ]\n",
      "  [ 128.6       ]]\n",
      "\n",
      " [[ 120.52421027]\n",
      "  [ 120.97214465]\n",
      "  [ 120.76310861]\n",
      "  ..., \n",
      "  [ 128.36      ]\n",
      "  [ 128.6       ]\n",
      "  [ 128.91      ]]\n",
      "\n",
      " [[ 120.97214465]\n",
      "  [ 120.76310861]\n",
      "  [ 120.46448569]\n",
      "  ..., \n",
      "  [ 128.6       ]\n",
      "  [ 128.91      ]\n",
      "  [ 128.97      ]]]\n",
      "\n",
      "\n",
      "Output labels:\n",
      "[[  39.35184442]\n",
      " [  39.2400494 ]\n",
      " [  38.38295431]\n",
      " ..., \n",
      " [ 128.91      ]\n",
      " [ 128.97      ]\n",
      " [ 129.18      ]]\n",
      "\n",
      "\n",
      "Query vector:\n",
      "[[[ 120.76310861]\n",
      "  [ 120.46448569]\n",
      "  [ 120.52421027]\n",
      "  ..., \n",
      "  [ 128.91      ]\n",
      "  [ 128.97      ]\n",
      "  [ 129.18      ]]]\n",
      "Train on 3942 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "3942/3942 [==============================] - 1s - loss: 411.1208 - mean_absolute_error: 9.0075 - val_loss: 1.0809 - val_mean_absolute_error: 0.9018\n",
      "Epoch 2/5\n",
      "3942/3942 [==============================] - 0s - loss: 23.6084 - mean_absolute_error: 3.5536 - val_loss: 1.1114 - val_mean_absolute_error: 0.9534\n",
      "Epoch 3/5\n",
      "3942/3942 [==============================] - 0s - loss: 20.3807 - mean_absolute_error: 3.3074 - val_loss: 16.3827 - val_mean_absolute_error: 3.8998\n",
      "Epoch 4/5\n",
      "3942/3942 [==============================] - 0s - loss: 17.3806 - mean_absolute_error: 3.0645 - val_loss: 1.5842 - val_mean_absolute_error: 1.0117\n",
      "Epoch 5/5\n",
      "3942/3942 [==============================] - 0s - loss: 14.6080 - mean_absolute_error: 2.8254 - val_loss: 7.3732 - val_mean_absolute_error: 2.4493\n",
      "\n",
      "\n",
      "actual\tpredicted\n",
      "127.38\t128.469\n",
      "127.29\t128.388\n",
      "127.07\t128.691\n",
      "126.86\t128.698\n",
      "126.79\t128.63\n",
      "127.05\t128.179\n",
      "126.93\t128.4\n",
      "126.64\t128.104\n",
      "126.91\t127.875\n",
      "127.16\t127.875\n",
      "126.81\t127.696\n",
      "126.67\t127.663\n",
      "124.81\t127.749\n",
      "125.04\t128.108\n",
      "126.32\t128.46\n",
      "126.2\t128.492\n",
      "126.43\t128.817\n",
      "124.42\t128.698\n",
      "124.21\t128.49\n",
      "124.39\t128.67\n",
      "125.64\t129.192\n",
      "125.26\t129.017\n",
      "125.06\t129.169\n",
      "125.36\t129.45\n",
      "125.41\t129.532\n",
      "125.46\t129.636\n",
      "126.12\t129.784\n",
      "126.98\t129.704\n",
      "127.27\t129.797\n",
      "126.29\t129.918\n",
      "126.64\t130.19\n",
      "126.58\t130.025\n",
      "126.49\t130.081\n",
      "127.85\t130.034\n",
      "128.34\t129.941\n",
      "128.4\t129.843\n",
      "128.36\t129.969\n",
      "128.6\t130.157\n",
      "128.91\t130.445\n",
      "128.97\t130.444\n",
      "129.18\t130.49\n",
      "next\t130.42039489746094\n",
      "[[[ 120.76310861]\n",
      "  [ 120.46448569]\n",
      "  [ 120.52421027]\n",
      "  ..., \n",
      "  [ 128.91      ]\n",
      "  [ 128.97      ]\n",
      "  [ 129.18      ]]]\n"
     ]
    }
   ],
   "source": [
    "    \"\"\"Prepare input data, build model, evaluate.\"\"\"\n",
    "    np.set_printoptions(threshold=25)\n",
    "    window_size = 120\n",
    "\n",
    "    timeseries = load_close('stockdatas/VTI.csv')\n",
    "    evaluate_timeseries(timeseries[0], window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
