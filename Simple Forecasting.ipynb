{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Forecasting\n",
    "\n",
    "## Our Focus problem are :\n",
    "- Regressiong Problem ( trying to get forecast exactly close price or return next day )\n",
    "- Binary classification problem ( price will go up [1;0] or down [0;1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "import matplotlib.pylab as plt\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "We want to predict t+1 value based on N previous days information (historical financial data).\n",
    "Example : having close prices from past 30 days on the market we want to predict, what price willl be tomorrow, on the 31th day.\n",
    "we will use 90% as training set and 10% as testing for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracy = []\n",
    "        self.predictions = []\n",
    "        self.i = 0\n",
    "        self.save_every = 5000\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracy.append(logs.get('acc'))\n",
    "        self.i += 1        \n",
    "        if self.i % self.save_every == 0:        \n",
    "            pred = model.predict(X_train)\n",
    "            self.predictions.append(pred)\n",
    "            \n",
    "def load_close():\n",
    "    f = open('stockdatas/SPY.csv', 'r').readlines()[1:]\n",
    "    raw_data = []\n",
    "    raw_dates = []\n",
    "    for line in f:\n",
    "        try:\n",
    "            close_price = float(line.split(',')[4])\n",
    "            raw_data.append(close_price)\n",
    "            raw_dates.append(line.split(',')[0])\n",
    "        except:\n",
    "            continue\n",
    "    return raw_data, raw_dates\n",
    "\n",
    "def load_returns():\n",
    "    f = open('stockdatas/SPY.csv', 'r').readlines()[1:]\n",
    "    raw_data = []\n",
    "    raw_dates = []\n",
    "    for line in f:\n",
    "        try:\n",
    "            open_price = float(line.split(',')[1])\n",
    "            close_price = float(line.split(',')[4])\n",
    "            raw_data.append(close_price - open_price)\n",
    "            raw_dates.append(line.split(',')[0])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return raw_data[::-1], raw_dates[::-1]\n",
    "\n",
    "def split_into_chunks(data, train, predict, step, binary=True, scale=True):\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(data), step):\n",
    "        try:\n",
    "            x_i = data[i:i+train]\n",
    "            y_i = data[i+train+predict]\n",
    "            \n",
    "            # Use it only for daily return time series\n",
    "            if binary:\n",
    "                if y_i > 0.:\n",
    "                    y_i = [1., 0.]\n",
    "                else:\n",
    "                    y_i = [0., 1.]\n",
    "\n",
    "                if scale: x_i = preprocessing.scale(x_i)\n",
    "                \n",
    "            else:\n",
    "                timeseries = np.array(data[i:i+train+predict])\n",
    "                if scale: timeseries = preprocessing.scale(timeseries)\n",
    "                x_i = timeseries[:-1]\n",
    "                y_i = timeseries[-1]\n",
    "            \n",
    "        except:\n",
    "            break\n",
    "\n",
    "        X.append(x_i)\n",
    "        Y.append(y_i)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b\n",
    "\n",
    "\n",
    "def create_Xt_Yt(X, y, percentage=0.9):\n",
    "    p = int(len(X) * percentage)\n",
    "    X_train = X[0:p]\n",
    "    Y_train = y[0:p]\n",
    "     \n",
    "    X_train, Y_train = shuffle_in_unison(X_train, Y_train)\n",
    " \n",
    "    X_test = X[p:]\n",
    "    Y_test = y[p:]\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression problem - Multi Layer Perceptron (MLP)\n",
    "\n",
    "It will be just 2 hidden layer perceptron. between 2 layers we add one dropout layer to prevent overfitting.\n",
    "\n",
    "Dense(1), Activation and mse in compile section is important thing. We want one output that can be any range (we predict real value) and our loss function is defined as mean squared error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries, dates = load_close()\n",
    "dates = [dt.datetime.strptime(d,'%Y-%m-%d').date() for d in dates]\n",
    "plt.plot(dates, timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 20 # 20 days close prices\n",
    "TARGET_TIME = 1 # predict the 21th day\n",
    "LAG_SIZE = 1\n",
    "EMB_SIZE = 1\n",
    "\n",
    "X, Y = split_into_chunks(timeseries, TRAIN_SIZE, TARGET_TIME, LAG_SIZE, binary=False, scale=False)\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y, percentage=0.9)\n",
    "\n",
    "Xp, Yp = split_into_chunks(timeseries, TRAIN_SIZE, TARGET_TIME, LAG_SIZE, binary=False, scale=False)\n",
    "Xp, Yp = np.array(Xp), np.array(Yp)\n",
    "X_trainp, X_testp, Y_trainp, Y_testp = create_Xt_Yt(Xp, Yp, percentage=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape = (TRAIN_SIZE, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(250))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse')\n",
    "\n",
    "model.fit(X_train, \n",
    "          Y_train, \n",
    "          epochs=5, \n",
    "          batch_size = 128, \n",
    "          verbose=1, \n",
    "          validation_split=0.1)\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"\\nScore :\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = []\n",
    "for xt in X_testp:\n",
    "    xt = np.array(xt)\n",
    "    mean_ = xt.mean()\n",
    "    scale_ = xt.std()\n",
    "    params.append([mean_, scale_])\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "new_predicted = []\n",
    "\n",
    "for pred, par in zip(predicted, params):\n",
    "    a = pred*par[1]\n",
    "    a += par[0]\n",
    "    new_predicted.append(a)\n",
    "    \n",
    "\n",
    "mse = mean_squared_error(predicted, new_predicted)\n",
    "print (\"Mean Squared Error : \",mse)\n",
    "\n",
    "try:\n",
    "    #plt.plot(Y_test[:150], color='black') # BLACK - trained RESULT\n",
    "    plt.plot(predicted[:150], color='blue') # BLUE - trained PREDICTION\n",
    "    plt.plot(Y_testp[:150], color='green') # GREEN - actual RESULT\n",
    "    #plt.plot(new_predicted[:150], color='red') # RED - restored PREDICTION\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print (str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression problem - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries, dates = load_returns()\n",
    "dates = [dt.datetime.strptime(d,'%Y-%m-%d').date() for d in dates]\n",
    "plt.plot(dates, timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 20\n",
    "TARGET_TIME = 1\n",
    "LAG_SIZE = 1\n",
    "EMB_SIZE = 1\n",
    "HIDDEN_RNN = 1\n",
    "\n",
    "X, Y = split_into_chunks(timeseries, TRAIN_SIZE, TARGET_TIME, LAG_SIZE, binary=True, scale=True)\n",
    "\n",
    "print (len(X), len(Y))\n",
    "\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y, percentage=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], EMB_SIZE))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], EMB_SIZE))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(input_shape = (EMB_SIZE,), input_dim=EMB_SIZE, output_dim=HIDDEN_RNN, return_sequences=True))\n",
    "model.add(LSTM(input_shape = (EMB_SIZE,), input_dim=EMB_SIZE, output_dim=HIDDEN_RNN, return_sequences=False))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, \n",
    "          Y_train, \n",
    "          epochs=5, \n",
    "          batch_size = 128, \n",
    "          verbose=1, \n",
    "          validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print (\"\\nScore :\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries, dates = load_returns()\n",
    "X, Y = split_into_chunks(timeseries, TRAIN_SIZE, TARGET_TIME, LAG_SIZE, binary=True)\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y, percentage=0.9)\n",
    "\n",
    "Y_train, Y_test = np.array([y.argmax() for y in Y_train]), np.array([y.argmax() for y in Y_test])\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics, svm\n",
    "from sklearn import linear_model\n",
    "\n",
    "print ('Training...')\n",
    "\n",
    "#classifier = RandomForestClassifier(n_estimators = 100,\n",
    "#                               n_jobs=4,\n",
    "#                               verbose=1)\n",
    "\n",
    "#classifier = linear_model.LogisticRegression(C=1e-5)\n",
    "\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "print ('Prediction...')\n",
    "predicted = classifier.predict(X_test)\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(Y_test, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problem - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 20 # 20 days close prices\n",
    "TARGET_TIME = 1 # predict the 21th day\n",
    "LAG_SIZE = 1\n",
    "EMB_SIZE = 1\n",
    "\n",
    "X, Y = split_into_chunks(timeseries, TRAIN_SIZE, TARGET_TIME, LAG_SIZE, binary=True, scale=True)\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y, percentage=0.9)\n",
    "\n",
    "Xp, Yp = split_into_chunks(timeseries, TRAIN_SIZE, TARGET_TIME, LAG_SIZE, binary=True, scale=True)\n",
    "Xp, Yp = np.array(Xp), np.array(Yp)\n",
    "X_trainp, X_testp, Y_trainp, Y_testp = create_Xt_Yt(Xp, Yp, percentage=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape = (TRAIN_SIZE, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(250))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam', \n",
    "\t\t\t  loss='binary_crossentropy', \n",
    "\t\t\t  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "          Y_train, \n",
    "          epochs=5, \n",
    "          batch_size = 128, \n",
    "          verbose=1, \n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"\\nModel Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problem - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(input_shape = (TRAIN_SIZE, EMB_SIZE), \n",
    "                        nb_filter=64,\n",
    "                        filter_length=2,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "model.add(Convolution1D(input_shape = (TRAIN_SIZE, EMB_SIZE), \n",
    "                        nb_filter=64,\n",
    "                        filter_length=2,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "history = TrainingHistory()\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "\t\t\t  loss='binary_crossentropy', \n",
    "\t\t\t  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, epochs=5,\n",
    "          validation_data=(X_test, Y_test), verbose=2)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Threating financial time series prediction as regression problem is better approach, it can learn the trend and prices close to the actual.\n",
    "\n",
    "MLPs are treating sequence data better as CNNs or RNNs which are supposed to work better with time series.\n",
    "\n",
    "future works :\n",
    "- Using different features (not only scaled time series) like techincal indicators, volume of sales\n",
    "- Try frequent data, minute-by minute to have more training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
