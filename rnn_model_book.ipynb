{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import os\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import *\n",
    "import keras\n",
    "import pandas_datareader.data as web\n",
    "import h5py\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def moving_average(group, n,center=False):\n",
    "    sma = pd.Series.rolling(group, window=n,center=center).mean()\n",
    "    return sma\n",
    "\n",
    "def bollinger_mid(group):\n",
    "    boll = pd.Series.rolling(group, window=20, center=False).mean()\n",
    "    return boll\n",
    "\n",
    "def exponential_moving_average(group, span,min_periods=1, ignore_na=False):\n",
    "    ema = pd.Series.ewm(group, min_periods=min_periods, adjust=True, span=span, ignore_na=ignore_na).mean()\n",
    "    return ema\n",
    "\n",
    "def moving_average_convergence(group, nslow=26, nfast=12):\n",
    "    emaslow = exponential_moving_average(group, nslow, 1)\n",
    "    emafast = exponential_moving_average(group, nfast, 1)\n",
    "    macd = emafast-emaslow\n",
    "    return macd\n",
    "\n",
    "def CCI(close, high, low, n=20, constant=0.015):\n",
    "    TP = (high + low + close) / 3\n",
    "    CCI = pd.Series((TP - pd.Series.rolling(TP, center=False,window=n).mean()) / (constant * pd.Series.rolling(TP,center=False,window=n).std()), name = 'CCI_' + str(n))\n",
    "    return CCI\n",
    "\n",
    "def ATR(df):\n",
    "    df['ATR1'] = abs (df['high'] - df['low'])\n",
    "    df['ATR2'] = abs (df['high'] - df['close'].shift())\n",
    "    df['ATR3'] = abs (df['low'] - df['close'].shift())\n",
    "    atr = df[['ATR1', 'ATR2', 'ATR3']].max(axis=1)\n",
    "    return atr\n",
    "\n",
    "def get_stock_data(stock_name, normalize=True, ma=[], macd=True, cci=True, atr=True, ema=[], bolling=True):\n",
    "    df = pd.read_csv('stockdatas/{}.csv'.format(stock_name))\n",
    "\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    # Percentage change\n",
    "    df['Pct'] = df['adjClose'].pct_change()\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Moving Average\n",
    "    if ma != []:\n",
    "        for x in ma:\n",
    "            df['{}MA'.format(x)] = moving_average(df['adjClose'], x)\n",
    "    if cci:\n",
    "        df['CCI'] = CCI(df['close'], df['high'], df['low'])\n",
    "    if macd:\n",
    "        df['MACD'] = moving_average_convergence(df['adjClose'])\n",
    "    if atr:\n",
    "        df['ATR'] = ATR(df)\n",
    "    if ema != []:\n",
    "        for y in ema:\n",
    "            df['{}EMA'.format(y)] = exponential_moving_average(df['adjClose'], span=x)\n",
    "    if bolling:\n",
    "        df['bolling'] = bollinger_mid(df['adjClose'])\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    if normalize:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1, 1))\n",
    "        df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1, 1))\n",
    "        df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1, 1))\n",
    "        df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1, 1))\n",
    "        df['adjClose'] = min_max_scaler.fit_transform(df['adjClose'].values.reshape(-1, 1))\n",
    "        df['Pct'] = min_max_scaler.fit_transform(df['Pct'].values.reshape(-1, 1))\n",
    "        if ma != []:\n",
    "            for x in ma:\n",
    "                df['{}MA'.format(x)] = min_max_scaler.fit_transform(\n",
    "                    df['{}MA'.format(x)].values.reshape(-1, 1))\n",
    "        if ema != []:\n",
    "            for y in ema:\n",
    "                df['{}EMA'.format(y)] = min_max_scaler.fit_transform(\n",
    "                    df['{}EMA'.format(y)].values.reshape(-1, 1))\n",
    "        if cci:\n",
    "            min_max_scaler.fit_transform(df['CCI'].values.reshape(-1, 1))\n",
    "        if macd:\n",
    "            min_max_scaler.fit_transform(df['MACD'].values.reshape(-1, 1))\n",
    "        if atr:\n",
    "            min_max_scaler.fit_transform(df['ATR'].values.reshape(-1, 1))\n",
    "        if bolling:\n",
    "            min_max_scaler.fit_transform(df['bolling'].values.reshape(-1, 1))\n",
    "\n",
    "    # move adj close to the rightmost\n",
    "    adj_close = df['adjClose']\n",
    "    df.drop(labels=['adjClose'], axis=1, inplace=True)\n",
    "    df = pd.concat([df, adj_close], axis=1)\n",
    "    return df\n",
    "\n",
    "def plot_stock(df):\n",
    "    print(df.head())\n",
    "    plt.subplot(211)\n",
    "    plt.plot(df['adjClose'], color='red', label='Adj Close')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(212)\n",
    "    plt.plot(df['pct'], color='blue', label='Percentage change')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def check_corr(df):\n",
    "    corr = df.corr()\n",
    "    ax = sns.heatmap(corr, cmap=\"BuGnYl\")\n",
    "    plt.show()\n",
    "\n",
    "def build_dataset(stock, seq_len, ratio=0.8):\n",
    "    num_of_features = len(stock.columns)\n",
    "    print(\"Number of features = {}\".format(num_of_features))\n",
    "    data = stock.as_matrix()\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "\n",
    "    for idx in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[idx: idx + sequence_length]) # index : index + 22days\n",
    "\n",
    "    result = np.array(result)\n",
    "    row = round(ratio * result.shape[0])\n",
    "    print (\"Total of training data = {}\".format(ratio * result.shape[0]))\n",
    "    print (\"Total of testing data = {}\".format(abs(1.0-ratio) * result.shape[0]))\n",
    "\n",
    "    train = result[:int(row), :]\n",
    "    X_train = train[:, :-1] # all data until day m\n",
    "    y_train = train[:, -1][:,-1] # day m + 1 adjusted close price\n",
    "\n",
    "    X_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], num_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], num_of_features))\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "def build_model(shape, neurons, dropout, optimizer, learning_rate, decay):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(neurons[0], input_shape=(shape[0], shape[1]), return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(LSTM(neurons[1], input_shape=(shape[0], shape[1]), return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))\n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "\n",
    "    opt = optimizer(lr=learning_rate, decay=decay)\n",
    "    model.compile(loss='mse',optimizer=opt, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# Result\n",
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]\n",
    "\n",
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p\n",
    "\n",
    "\n",
    "def denormalize(stock_name, normalized_value):\n",
    "    df = pd.read_csv('stockdatas/{}.csv'.format(stock_name))\n",
    "    #df.drop(['open','high','low','close','volume'], 1, inplace=True)\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df = df['adjClose'].values.reshape(-1, 1)\n",
    "    normalized_value = normalized_value.reshape(-1, 1)\n",
    "\n",
    "    # return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "\n",
    "    return new\n",
    "\n",
    "def plot_result(stock_name, normalized_value_p, normalized_value_y_test):\n",
    "    newp = denormalize(stock_name, normalized_value_p)\n",
    "    newy_test = denormalize(stock_name, normalized_value_y_test)\n",
    "    plt2.plot(newp, color='red', label='Prediction')\n",
    "    plt2.plot(newy_test,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.title('The test result for {}'.format(stock_name))\n",
    "    plt2.xlabel('Days')\n",
    "    plt2.ylabel('Adjusted Close')\n",
    "    plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ros/anaconda3/envs/research/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# model configuration\n",
    "seq_len = 22 # the window frame of the past data\n",
    "num_of_features = 17\n",
    "shape = [seq_len, num_of_features, 1]\n",
    "neurons = [256, 256, 32, 1]\n",
    "dropout = 0.3\n",
    "optimizer = Adam\n",
    "learning_rate = 0.01\n",
    "decay = 0.5\n",
    "epochs = 90\n",
    "stock_name = 'AAPL'\n",
    "\n",
    "df = get_stock_data(stock_name, ma=[5,10], ema=[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 17\n",
      "Total of training data = 3533.6000000000004\n",
      "Total of testing data = 883.3999999999997\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = build_dataset(df, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 22, 256)           280576    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 814,145\n",
      "Trainable params: 814,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2827 samples, validate on 707 samples\n",
      "Epoch 1/90\n",
      "2827/2827 [==============================] - 4s - loss: 0.0128 - acc: 3.5373e-04 - val_loss: 0.1195 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "2827/2827 [==============================] - 3s - loss: 0.0031 - acc: 3.5373e-04 - val_loss: 0.0541 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "2827/2827 [==============================] - 4s - loss: 0.0013 - acc: 3.5373e-04 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "2827/2827 [==============================] - 4s - loss: 7.5009e-04 - acc: 3.5373e-04 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "2827/2827 [==============================] - 4s - loss: 4.8362e-04 - acc: 3.5373e-04 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "2827/2827 [==============================] - 4s - loss: 3.8928e-04 - acc: 3.5373e-04 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "2827/2827 [==============================] - 4s - loss: 3.3163e-04 - acc: 3.5373e-04 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "2827/2827 [==============================] - 3s - loss: 2.7663e-04 - acc: 3.5373e-04 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "2827/2827 [==============================] - 3s - loss: 2.3655e-04 - acc: 3.5373e-04 - val_loss: 0.0211 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "2827/2827 [==============================] - 3s - loss: 2.3841e-04 - acc: 3.5373e-04 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "2827/2827 [==============================] - 3s - loss: 2.0948e-04 - acc: 3.5373e-04 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.9874e-04 - acc: 3.5373e-04 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "2827/2827 [==============================] - 4s - loss: 2.0189e-04 - acc: 3.5373e-04 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.7877e-04 - acc: 3.5373e-04 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.7194e-04 - acc: 3.5373e-04 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.6429e-04 - acc: 3.5373e-04 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.5329e-04 - acc: 3.5373e-04 - val_loss: 0.0185 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.4979e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.5035e-04 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.5302e-04 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.4985e-04 - acc: 3.5373e-04 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.4787e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.3767e-04 - acc: 3.5373e-04 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.4025e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.3360e-04 - acc: 3.5373e-04 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.3450e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.2730e-04 - acc: 3.5373e-04 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.2405e-04 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.3381e-04 - acc: 3.5373e-04 - val_loss: 0.0209 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.3120e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.1727e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.1970e-04 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.1149e-04 - acc: 3.5373e-04 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.1413e-04 - acc: 3.5373e-04 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.2099e-04 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.1445e-04 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.1643e-04 - acc: 3.5373e-04 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.0900e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0793e-04 - acc: 3.5373e-04 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.1920e-04 - acc: 3.5373e-04 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.1025e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0490e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0902e-04 - acc: 3.5373e-04 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.1056e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0521e-04 - acc: 3.5373e-04 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0767e-04 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0352e-04 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0390e-04 - acc: 3.5373e-04 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0838e-04 - acc: 3.5373e-04 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0663e-04 - acc: 3.5373e-04 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0059e-04 - acc: 3.5373e-04 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2827/2827 [==============================] - 3s - loss: 9.5309e-05 - acc: 3.5373e-04 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.9141e-05 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0116e-04 - acc: 3.5373e-04 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.3645e-05 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "2827/2827 [==============================] - 4s - loss: 1.0412e-04 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.5217e-05 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.7448e-05 - acc: 3.5373e-04 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.7880e-05 - acc: 3.5373e-04 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.7639e-05 - acc: 3.5373e-04 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "2827/2827 [==============================] - 4s - loss: 9.4741e-05 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "2827/2827 [==============================] - 4s - loss: 9.2340e-05 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "2827/2827 [==============================] - 4s - loss: 9.7293e-05 - acc: 3.5373e-04 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "2827/2827 [==============================] - 3s - loss: 1.0018e-04 - acc: 3.5373e-04 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.1961e-05 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.6657e-05 - acc: 3.5373e-04 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "2827/2827 [==============================] - 4s - loss: 9.1717e-05 - acc: 3.5373e-04 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.3367e-05 - acc: 3.5373e-04 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.9106e-05 - acc: 3.5373e-04 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "2827/2827 [==============================] - 4s - loss: 9.1245e-05 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "2827/2827 [==============================] - 4s - loss: 9.3378e-05 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.6789e-05 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "2827/2827 [==============================] - 3s - loss: 9.4961e-05 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.6986e-05 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "2827/2827 [==============================] - 4s - loss: 9.1306e-05 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.7120e-05 - acc: 3.5373e-04 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "2827/2827 [==============================] - 4s - loss: 8.4092e-05 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.9597e-05 - acc: 3.5373e-04 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.4944e-05 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.6011e-05 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.4543e-05 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.0863e-05 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.4544e-05 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.7753e-05 - acc: 3.5373e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.4311e-05 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.3816e-05 - acc: 3.5373e-04 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "2827/2827 [==============================] - 4s - loss: 8.3478e-05 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.2050e-05 - acc: 3.5373e-04 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.4543e-05 - acc: 3.5373e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "2827/2827 [==============================] - 3s - loss: 8.6738e-05 - acc: 3.5373e-04 - val_loss: 0.0203 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc0e34937f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(shape, neurons, dropout, optimizer, learning_rate, decay)\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00408 MSE (0.06 RMSE)\n",
      "Test Score: 0.32784 MSE (0.57 RMSE)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc0e0385da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_score(model, X_train, y_train, X_test, y_test)\n",
    "p = percentage_difference(model, X_test, y_test)\n",
    "plot_result(stock_name, p, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
